{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE_MAPPING = {\n",
    "    \"gpu\": torch.cuda,\n",
    "    \"mps\": torch.backends.mps,\n",
    "}\n",
    "\n",
    "def get_torch_device(device_mapping: dict) -> torch.device:\n",
    "    \"\"\"gets the best performant device (CPU or MPS)\"\"\"\n",
    "    for device_name, device in device_mapping.items():\n",
    "        if device.is_available():\n",
    "            return torch.device(device_name)\n",
    "\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# device = get_torch_device(DEVICE_MAPPING)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.datasets.planetoid.Planetoid"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features: int, hidden_size: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_size)\n",
    "        self.hidden = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=.5, training=self.training)\n",
    "        # print(f'Input shape: {x.shape}')\n",
    "\n",
    "        # x = self.hidden(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, p=.75, training=self.training)\n",
    "        # print(f'Hidden shape: {x.shape}')\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # print(f'Output shape: {x.shape}')\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:00<00:00, 209.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.9512697458267212, Test loss: 1.9435139894485474\n",
      "Epoch: 10, Train loss: 1.6566219329833984, Test loss: 1.7884819507598877\n",
      "Epoch: 20, Train loss: 1.3158575296401978, Test loss: 1.5770905017852783\n",
      "Epoch: 30, Train loss: 0.943773090839386, Test loss: 1.3503844738006592\n",
      "Epoch: 40, Train loss: 0.6710296273231506, Test loss: 1.1711639165878296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [00:00<00:00, 210.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.4513654410839081, Test loss: 1.0223459005355835\n",
      "Epoch: 60, Train loss: 0.33539119362831116, Test loss: 0.919208288192749\n",
      "Epoch: 70, Train loss: 0.23925192654132843, Test loss: 0.8552830815315247\n",
      "Epoch: 80, Train loss: 0.19442668557167053, Test loss: 0.8092189431190491\n",
      "Epoch: 90, Train loss: 0.14211392402648926, Test loss: 0.7684388756752014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 133/200 [00:00<00:00, 223.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train loss: 0.1280958652496338, Test loss: 0.7645316123962402\n",
      "Epoch: 110, Train loss: 0.09636207669973373, Test loss: 0.7286208271980286\n",
      "Epoch: 120, Train loss: 0.09051734209060669, Test loss: 0.7305976152420044\n",
      "Epoch: 130, Train loss: 0.07303255051374435, Test loss: 0.7083525061607361\n",
      "Epoch: 140, Train loss: 0.0733623132109642, Test loss: 0.7094988822937012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [00:00<00:00, 227.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Train loss: 0.059924207627773285, Test loss: 0.6920695304870605\n",
      "Epoch: 160, Train loss: 0.059165921062231064, Test loss: 0.6927162408828735\n",
      "Epoch: 170, Train loss: 0.05422285199165344, Test loss: 0.697075605392456\n",
      "Epoch: 180, Train loss: 0.049243487417697906, Test loss: 0.6923565864562988\n",
      "Epoch: 190, Train loss: 0.04270246997475624, Test loss: 0.6847146153450012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 220.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model = GCN(num_features=dataset.num_node_features, hidden_size=64, num_classes=dataset.num_classes).to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    test_loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "    if epoch % 10 == 0:  # print every 10th epoch\n",
    "        print(f'Epoch: {epoch}, Train loss: {loss.item()}, Test loss: {test_loss.item()}')\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7940\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False], device='mps:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 1, 3, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   4,   4,   6,   5,   2,   8],\n",
       "       [  6,  80,   3,   2,   0,   0,   0],\n",
       "       [  3,   7, 131,   3,   0,   0,   0],\n",
       "       [ 25,  12,  15, 226,  30,   8,   3],\n",
       "       [  7,   2,   2,   5, 127,   5,   1],\n",
       "       [ 11,   4,   4,   1,   0,  75,   8],\n",
       "       [  5,   2,   0,   1,   0,   2,  54]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(data.y[data.test_mask].cpu().numpy(), pred[data.test_mask].cpu().numpy())\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
